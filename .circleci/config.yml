version: 2.1

jobs:
  integration-postgres:
    docker:
      - image: cimg/python:3.11
      - image: cimg/postgres:16.0
        environment:
          POSTGRES_USER: dbt
          POSTGRES_PASSWORD: dbt
          POSTGRES_DB: dbt

    resource_class: small

    environment:
      DBT_PROFILES_DIR: ./
      INTEGRATION_TEST_RELATION: test_data_default
      INTEGRATION_TEST_SCHEMA: dbt_profiler_integration_tests_postgres
      POSTGRES_HOST: localhost

    working_directory: ~/repo/integration_tests

    steps:
      - checkout:
          path: ~/repo
      - run:
          name: Install dependencies
          command: |
            pip install "dbt-postgres>=1.10.0,<2.0.0"
            dbt deps
            dbt --version

      - run:
          name: Run tests
          command: |
            dbt build --target postgres

      - run:
          name: Run print_profile macro
          command: |
            dbt run-operation print_profile --args '{"relation_name": "'$INTEGRATION_TEST_RELATION'", "schema": "'$INTEGRATION_TEST_SCHEMA'"}'

      - run:
          name: Run print_profile_schema macro
          command: |
            dbt run-operation print_profile_schema --args '{"relation_name": "'$INTEGRATION_TEST_RELATION'", "schema": "'$INTEGRATION_TEST_SCHEMA'"}'

      - run:
          name: Run print_profile_docs macro
          command: |
            dbt run-operation print_profile_docs --args '{"relation_name": "'$INTEGRATION_TEST_RELATION'", "schema": "'$INTEGRATION_TEST_SCHEMA'"}'

      - run:
          name: Run update-relation-profile.sh script
          command: ../update-relation-profile.sh $INTEGRATION_TEST_RELATION $INTEGRATION_TEST_SCHEMA

  integration-sqlserver:
    docker:
      - image: cimg/python:3.11
      - image: mcr.microsoft.com/mssql/server:2022-latest
        environment:
          ACCEPT_EULA: Y
          MSSQL_SA_PASSWORD: "Dbt_profiler_ci_1!"

    resource_class: medium

    environment:
      DBT_PROFILES_DIR: ./

    working_directory: ~/repo/integration_tests

    steps:
      - checkout:
          path: ~/repo
      - run:
          name: Install ODBC driver
          command: |
            curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc
            curl https://packages.microsoft.com/config/ubuntu/22.04/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list
            sudo apt-get update
            sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18 unixodbc-dev
      - run:
          name: Install dependencies
          command: |
            pip install "dbt-sqlserver>=1.10.0,<2.0.0"
            dbt deps
            dbt --version
      - run:
          name: Wait for SQL Server to be ready
          command: sleep 30
      - run:
          name: Run tests
          command: |
            dbt build --target sqlserver

  integration-bigquery:
    docker:
      - image: cimg/python:3.11

    resource_class: small

    environment:
      DBT_PROFILES_DIR: ./
      BIGQUERY_KEYFILE: ./bigquery-service-key.json

    working_directory: ~/repo/integration_tests

    steps:
      - checkout:
          path: ~/repo
      - run:
          name: Install dependencies
          command: |
            pip install "dbt-bigquery>=1.10.0,<2.0.0"
            dbt deps
            dbt --version

      - run:
          name: Test database connection
          command: |
            echo "${BIGQUERY_SERVICE_ACCOUNT_JSON}" > ${BIGQUERY_KEYFILE}
            dbt debug --target bigquery

      - run:
          name: Run tests
          command: |
            dbt build --target bigquery

  integration-snowflake:
    docker:
      - image: cimg/python:3.11

    resource_class: small

    environment:
      DBT_PROFILES_DIR: ./

    working_directory: ~/repo/integration_tests

    steps:
      - checkout:
          path: ~/repo
      - run:
          name: Install dependencies
          command: |
            pip install "dbt-snowflake>=1.10.0,<2.0.0"
            dbt deps
            dbt --version

      - run:
          name: Prepare Snowflake private key
          command: |
            # The SNOWFLAKE_PRIVATE_KEY CI secret stores the PEM key with spaces
            # instead of newlines. Reformat it to proper PEM before running dbt.
            python3 -c "import os; key=os.environ['SNOWFLAKE_PRIVATE_KEY']; parts=key.split('-----'); b64=parts[2].strip().replace(' ', chr(10)); formatted='-----'+parts[1]+'-----'+chr(10)+b64+chr(10)+'-----'+parts[3]+'-----'; open(os.environ['BASH_ENV'], 'a').write('export SNOWFLAKE_PRIVATE_KEY='+chr(39)+formatted+chr(39)+chr(10))"

      - run:
          name: Test database connection
          command: |
            dbt debug --target snowflake

      - run:
          name: Run tests
          command: |
            dbt build --target snowflake

  integration-snowflake-fusion:
    docker:
      - image: cimg/python:3.11

    resource_class: small

    environment:
      DBT_PROFILES_DIR: ./
      SHELL: /bin/bash
      # dbt Fusion evaluates all env_var() calls in profiles.yml on load,
      # not just the active target. Set dummy values for unused profiles.
      POSTGRES_HOST: unused
      BIGQUERY_PROJECT: unused
      BIGQUERY_KEYFILE: unused

    working_directory: ~/repo/integration_tests

    steps:
      - checkout:
          path: ~/repo
      - run:
          name: Install dbt Fusion
          command: |
            curl -fsSL https://public.cdn.getdbt.com/fs/install/install.sh | sh -s -- --update
      - run:
          name: Install package dependencies
          command: |
            export PATH="$HOME/.local/bin:$PATH"
            dbt deps
            dbt --version
      - run:
          name: Prepare Snowflake private key
          command: |
            # The SNOWFLAKE_PRIVATE_KEY CI secret stores the PEM key with spaces
            # instead of newlines. Reformat it to proper PEM before running dbt.
            python3 -c "import os; key=os.environ['SNOWFLAKE_PRIVATE_KEY']; parts=key.split('-----'); b64=parts[2].strip().replace(' ', chr(10)); formatted='-----'+parts[1]+'-----'+chr(10)+b64+chr(10)+'-----'+parts[3]+'-----'; open(os.environ['BASH_ENV'], 'a').write('export SNOWFLAKE_PRIVATE_KEY='+chr(39)+formatted+chr(39)+chr(10))"
      - run:
          name: Test database connection
          command: |
            export PATH="$HOME/.local/bin:$PATH"
            dbt debug --target snowflake
      - run:
          name: Run tests
          command: |
            export PATH="$HOME/.local/bin:$PATH"
            dbt build --target snowflake

workflows:
  version: 2
  continuous-integration:
    jobs:
      - integration-postgres
      - integration-sqlserver
      - approve-bigquery:
          type: approval
      - integration-bigquery:
          requires:
            - approve-bigquery
      - approve-snowflake:
          type: approval
      - integration-snowflake:
          requires:
            - approve-snowflake
      - approve-snowflake-fusion:
          type: approval
      - integration-snowflake-fusion:
          requires:
            - approve-snowflake-fusion